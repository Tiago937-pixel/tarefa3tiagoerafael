import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import seaborn as sns
import matplotlib.pyplot as plt

# Machine Learning
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.feature_selection import RFE
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import (accuracy_score, roc_auc_score, precision_score, 
                           recall_score, f1_score, confusion_matrix, roc_curve,
                           classification_report)
from imblearn.over_sampling import SMOTE
import statsmodels.api as sm
from statsmodels.stats.outliers_influence import variance_inflation_factor

# Warnings
import warnings
warnings.filterwarnings('ignore')

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="üè® An√°lise de Cancelamento de Reservas Hoteleiras",
    page_icon="üè®",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS customizado
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #1e3c72 0%, #2a5298 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-container {
        background: #f0f2f6;
        padding: 1rem;
        border-radius: 10px;
        border-left: 4px solid #1e3c72;
    }
    .insight-box {
        background: #e8f4fd;
        padding: 1rem;
        border-radius: 10px;
        border-left: 4px solid #2196F3;
        margin: 1rem 0;
    }
    .warning-box {
        background: #fff3cd;
        padding: 1rem;
        border-radius: 10px;
        border-left: 4px solid #ffc107;
        margin: 1rem 0;
    }
    .success-box {
        background: #d4edda;
        padding: 1rem;
        border-radius: 10px;
        border-left: 4px solid #28a745;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# Header principal
st.markdown("""
<div class="main-header">
    <h1>üè® Sistema Inteligente de Predi√ß√£o de Cancelamentos</h1>
    <h3>An√°lise Avan√ßada com Regress√£o Log√≠stica | Professor Jo√£o Gabriel</h3>
    <p>Universidade de Bras√≠lia - Engenharia de Produ√ß√£o</p>
</div>
""", unsafe_allow_html=True)

@st.cache_data
def load_data():
    """Carrega e processa os dados do hotel"""
    try:
        # Tentativa de carregar de diferentes localiza√ß√µes
        possible_paths = [
            'hotel_bookings.csv',
            'data/hotel_bookings.csv', 
            'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv'
        ]
        
        for path in possible_paths:
            try:
                data = pd.read_csv(path)
                if 'is_canceled' in data.columns:
                    return data
            except:
                continue
                
        # Se n√£o conseguir carregar, criar dados sint√©ticos para demonstra√ß√£o
        st.warning("‚ö†Ô∏è Arquivo de dados n√£o encontrado. Gerando dados sint√©ticos para demonstra√ß√£o.")
        return generate_synthetic_data()
        
    except Exception as e:
        st.error(f"Erro ao carregar dados: {e}")
        return generate_synthetic_data()

def generate_synthetic_data():
    """Gera dados sint√©ticos realistas para demonstra√ß√£o"""
    np.random.seed(42)
    n = 10000
    
    # Vari√°veis categ√≥ricas
    hotels = np.random.choice(['Resort Hotel', 'City Hotel'], n, p=[0.3, 0.7])
    arrival_months = np.random.choice(['January', 'February', 'March', 'April', 'May', 
                                     'June', 'July', 'August', 'September', 'October', 
                                     'November', 'December'], n)
    customer_types = np.random.choice(['Transient', 'Contract', 'Group', 'Transient-Party'], 
                                    n, p=[0.7, 0.1, 0.1, 0.1])
    market_segments = np.random.choice(['Online TA', 'Direct', 'Corporate', 'Groups', 'Offline TA'], 
                                     n, p=[0.4, 0.2, 0.2, 0.1, 0.1])
    meal_plans = np.random.choice(['BB', 'HB', 'FB', 'SC'], n, p=[0.6, 0.2, 0.1, 0.1])
    
    # Vari√°veis num√©ricas
    lead_time = np.random.exponential(30, n).astype(int)
    stays_in_weekend_nights = np.random.poisson(1, n)
    stays_in_week_nights = np.random.poisson(2, n)
    adults = np.random.choice([1, 2, 3, 4], n, p=[0.2, 0.6, 0.15, 0.05])
    children = np.random.choice([0, 1, 2], n, p=[0.8, 0.15, 0.05])
    babies = np.random.choice([0, 1], n, p=[0.95, 0.05])
    adr = np.random.gamma(2, 50, n)
    total_of_special_requests = np.random.poisson(0.5, n)
    booking_changes = np.random.poisson(0.2, n)
    previous_cancellations = np.random.poisson(0.1, n)
    required_car_parking_spaces = np.random.choice([0, 1], n, p=[0.9, 0.1])
    
    # Criar vari√°vel target com l√≥gica real√≠stica
    prob_cancel = (
        0.1 +  # baseline
        0.3 * (lead_time > 60) +  # lead time alto
        0.2 * (adr > 150) +  # pre√ßo alto
        0.15 * (booking_changes > 0) +  # mudan√ßas na reserva
        0.25 * (previous_cancellations > 0) +  # hist√≥rico de cancelamento
        0.1 * (customer_types == 'Transient') +  # tipo de cliente
        -0.1 * (total_of_special_requests > 0)  # solicita√ß√µes especiais reduzem cancelamento
    )
    prob_cancel = np.clip(prob_cancel, 0, 0.8)
    is_canceled = np.random.binomial(1, prob_cancel, n)
    
    # Criar DataFrame
    data = pd.DataFrame({
        'hotel': hotels,
        'is_canceled': is_canceled,
        'lead_time': lead_time,
        'arrival_date_month': arrival_months,
        'stays_in_weekend_nights': stays_in_weekend_nights,
        'stays_in_week_nights': stays_in_week_nights,
        'adults': adults,
        'children': children,
        'babies': babies,
        'meal': meal_plans,
        'market_segment': market_segments,
        'customer_type': customer_types,
        'adr': adr,
        'total_of_special_requests': total_of_special_requests,
        'booking_changes': booking_changes,
        'previous_cancellations': previous_cancellations,
        'required_car_parking_spaces': required_car_parking_spaces,
        'is_repeated_guest': np.random.choice([0, 1], n, p=[0.9, 0.1])
    })
    
    return data

def prepare_data(data):
    """Prepara os dados para modelagem"""
    # Criar c√≥pias para n√£o modificar os dados originais
    df = data.copy()
    
    # Encoding de vari√°veis categ√≥ricas
    categorical_cols = ['hotel', 'arrival_date_month', 'meal', 'market_segment', 'customer_type']
    df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)
    
    return df_encoded

def calculate_vif(X):
    """Calcula o Variance Inflation Factor para detectar multicolinearidade"""
    vif_data = pd.DataFrame()
    vif_data["Vari√°vel"] = X.columns
    vif_data["VIF"] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))]
    return vif_data.sort_values('VIF', ascending=False)

# Carregar dados
data = load_data()

# Sidebar para navega√ß√£o
st.sidebar.title("üìã Navega√ß√£o")
page = st.sidebar.selectbox(
    "Escolha a an√°lise:",
    ["üè† Vis√£o Geral", "üìä An√°lise Explorat√≥ria", "ü§ñ Modelagem Preditiva", 
     "üîç Valida√ß√£o de Pressupostos", "üíº Recomenda√ß√µes Estrat√©gicas", "üéØ Simulador de Cen√°rios"]
)

if page == "üè† Vis√£o Geral":
    st.header("üìà Vis√£o Geral do Dataset")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown("""
        <div class="metric-container">
            <h3>{:,}</h3>
            <p>Total de Reservas</p>
        </div>
        """.format(len(data)), unsafe_allow_html=True)
    
    with col2:
        cancel_rate = data['is_canceled'].mean()
        st.markdown("""
        <div class="metric-container">
            <h3>{:.1f}%</h3>
            <p>Taxa de Cancelamento</p>
        </div>
        """.format(cancel_rate * 100), unsafe_allow_html=True)
    
    with col3:
        avg_adr = data['adr'].mean() if 'adr' in data.columns else 0
        st.markdown("""
        <div class="metric-container">
            <h3>${:.0f}</h3>
            <p>ADR M√©dio</p>
        </div>
        """.format(avg_adr), unsafe_allow_html=True)
    
    with col4:
        avg_lead_time = data['lead_time'].mean() if 'lead_time' in data.columns else 0
        st.markdown("""
        <div class="metric-container">
            <h3>{:.0f} dias</h3>
            <p>Lead Time M√©dio</p>
        </div>
        """.format(avg_lead_time), unsafe_allow_html=True)
    
    st.subheader("üìã Estrutura dos Dados")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**Informa√ß√µes do Dataset:**")
        st.write(f"‚Ä¢ Linhas: {data.shape[0]:,}")
        st.write(f"‚Ä¢ Colunas: {data.shape[1]}")
        st.write(f"‚Ä¢ Valores faltantes: {data.isnull().sum().sum()}")
        
    with col2:
        st.write("**Distribui√ß√£o da Vari√°vel Target:**")
        target_dist = data['is_canceled'].value_counts()
        st.write(f"‚Ä¢ N√£o canceladas: {target_dist[0]:,} ({target_dist[0]/len(data)*100:.1f}%)")
        st.write(f"‚Ä¢ Canceladas: {target_dist[1]:,} ({target_dist[1]/len(data)*100:.1f}%)")
    
    # Visualiza√ß√£o da distribui√ß√£o
    fig = make_subplots(
        rows=1, cols=2,
        subplot_titles=["Distribui√ß√£o de Cancelamentos", "Cancelamentos por Tipo de Hotel"],
        specs=[[{"type": "pie"}, {"type": "bar"}]]
    )
    
    # Gr√°fico de pizza
    labels = ['N√£o Cancelada', 'Cancelada']
    values = data['is_canceled'].value_counts()
    fig.add_trace(
        go.Pie(labels=labels, values=values, hole=0.4, name=""),
        row=1, col=1
    )
    
    # Gr√°fico de barras por hotel
    if 'hotel' in data.columns:
        hotel_cancel = data.groupby('hotel')['is_canceled'].agg(['count', 'mean']).reset_index()
        fig.add_trace(
            go.Bar(x=hotel_cancel['hotel'], y=hotel_cancel['mean']*100, name="Taxa de Cancelamento (%)"),
            row=1, col=2
        )
    
    fig.update_layout(height=400, showlegend=True)
    st.plotly_chart(fig, use_container_width=True)
    
    # Preview dos dados
    st.subheader("üîç Preview dos Dados")
    st.dataframe(data.head(10))

elif page == "üìä An√°lise Explorat√≥ria":
    st.header("üìä An√°lise Explorat√≥ria dos Dados")
    
    tab1, tab2, tab3 = st.tabs(["üî¢ Vari√°veis Num√©ricas", "üìù Vari√°veis Categ√≥ricas", "üîó Correla√ß√µes"])
    
    with tab1:
        st.subheader("An√°lise de Vari√°veis Num√©ricas")
        
        numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
        if 'is_canceled' in numeric_cols:
            numeric_cols.remove('is_canceled')
        
        selected_numeric = st.multiselect(
            "Selecione as vari√°veis num√©ricas para an√°lise:",
            numeric_cols,
            default=numeric_cols[:4] if len(numeric_cols) >= 4 else numeric_cols
        )
        
        if selected_numeric:
            # Estat√≠sticas descritivas
            st.write("**Estat√≠sticas Descritivas:**")
            st.dataframe(data[selected_numeric].describe())
            
            # Distribui√ß√µes
            fig = make_subplots(
                rows=2, cols=2,
                subplot_titles=selected_numeric[:4],
                specs=[[{"secondary_y": False}, {"secondary_y": False}],
                       [{"secondary_y": False}, {"secondary_y": False}]]
            )
            
            for i, col in enumerate(selected_numeric[:4]):
                row = i // 2 + 1
                col_pos = i % 2 + 1
                
                fig.add_trace(
                    go.Histogram(x=data[col], name=col, opacity=0.7),
                    row=row, col=col_pos
                )
            
            fig.update_layout(height=600, showlegend=False)
            st.plotly_chart(fig, use_container_width=True)
            
            # Boxplots por cancelamento
            st.subheader("üì¶ Distribui√ß√£o por Status de Cancelamento")
            
            selected_for_box = st.selectbox("Escolha uma vari√°vel para an√°lise detalhada:", selected_numeric)
            
            fig = px.box(data, x='is_canceled', y=selected_for_box, 
                        title=f"Distribui√ß√£o de {selected_for_box} por Status de Cancelamento",
                        labels={'is_canceled': 'Cancelado (0=N√£o, 1=Sim)'})
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        st.subheader("An√°lise de Vari√°veis Categ√≥ricas")
        
        categorical_cols = data.select_dtypes(include=['object']).columns.tolist()
        
        if categorical_cols:
            selected_cat = st.selectbox("Selecione uma vari√°vel categ√≥rica:", categorical_cols)
            
            col1, col2 = st.columns(2)
            
            with col1:
                # Distribui√ß√£o geral
                value_counts = data[selected_cat].value_counts()
                fig = px.pie(values=value_counts.values, names=value_counts.index,
                           title=f"Distribui√ß√£o de {selected_cat}")
                st.plotly_chart(fig)
            
            with col2:
                # Taxa de cancelamento por categoria
                cancel_by_cat = data.groupby(selected_cat)['is_canceled'].agg(['count', 'mean']).reset_index()
                cancel_by_cat['cancel_rate'] = cancel_by_cat['mean'] * 100
                
                fig = px.bar(cancel_by_cat, x=selected_cat, y='cancel_rate',
                           title=f"Taxa de Cancelamento por {selected_cat}")
                fig.update_layout(yaxis_title="Taxa de Cancelamento (%)")
                st.plotly_chart(fig)
            
            # Tabela de conting√™ncia
            st.write("**Tabela de Conting√™ncia:**")
            contingency = pd.crosstab(data[selected_cat], data['is_canceled'], margins=True)
            st.dataframe(contingency)
    
    with tab3:
        st.subheader("üîó An√°lise de Correla√ß√µes")
        
        # Matriz de correla√ß√£o
        numeric_data = data.select_dtypes(include=[np.number])
        corr_matrix = numeric_data.corr()
        
        fig = px.imshow(corr_matrix, 
                       title="Matriz de Correla√ß√£o",
                       color_continuous_scale="RdBu",
                       aspect="auto")
        fig.update_layout(height=600)
        st.plotly_chart(fig, use_container_width=True)
        
        # Correla√ß√µes com a vari√°vel target
        target_corr = corr_matrix['is_canceled'].abs().sort_values(ascending=False)[1:]
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**Correla√ß√µes com Cancelamento (em ordem decrescente):**")
            st.dataframe(target_corr.to_frame('Correla√ß√£o Absoluta'))
        
        with col2:
            fig = px.bar(x=target_corr.values, y=target_corr.index,
                        orientation='h',
                        title="Correla√ß√£o com Cancelamento",
                        labels={'x': 'Correla√ß√£o Absoluta', 'y': 'Vari√°veis'})
            st.plotly_chart(fig)

elif page == "ü§ñ Modelagem Preditiva":
    st.header("ü§ñ Modelagem Preditiva com Regress√£o Log√≠stica")
    
    # Sidebar para configura√ß√µes do modelo
    st.sidebar.subheader("‚öôÔ∏è Configura√ß√µes do Modelo")
    
    test_size = st.sidebar.slider("Tamanho do conjunto de teste", 0.1, 0.5, 0.3, 0.05)
    apply_smote = st.sidebar.checkbox("Aplicar SMOTE", value=True)
    apply_rfe = st.sidebar.checkbox("Aplicar RFE", value=True)
    
    if apply_rfe:
        n_features = st.sidebar.slider("N√∫mero de features (RFE)", 5, 20, 12)
    
    random_state = st.sidebar.number_input("Random State", value=42)
    
    # Preparar dados
    df_processed = prepare_data(data)
    
    # Separar features e target
    X = df_processed.drop('is_canceled', axis=1)
    y = df_processed['is_canceled']
    
    # Divis√£o treino/teste
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state, stratify=y
    )
    
    # Aplicar SMOTE se selecionado
    if apply_smote:
        smote = SMOTE(random_state=random_state)
        X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)
        st.success(f"‚úÖ SMOTE aplicado: {len(X_train):,} ‚Üí {len(X_train_balanced):,} amostras")
    else:
        X_train_balanced, y_train_balanced = X_train, y_train
        st.info("‚ÑπÔ∏è SMOTE n√£o aplicado - dados originais mantidos")
    
    # Aplicar RFE se selecionado
    if apply_rfe:
        rfe = RFE(estimator=LogisticRegression(random_state=random_state), n_features_to_select=n_features)
        X_train_selected = rfe.fit_transform(X_train_balanced, y_train_balanced)
        X_test_selected = rfe.transform(X_test)
        selected_features = X.columns[rfe.support_].tolist()
        
        st.success(f"‚úÖ RFE aplicado: {len(X.columns)} ‚Üí {len(selected_features)} vari√°veis")
        
        with st.expander("üîç Vari√°veis Selecionadas pelo RFE"):
            col1, col2 = st.columns(2)
            with col1:
                st.write("**Vari√°veis Selecionadas:**")
                for feat in selected_features:
                    st.write(f"‚Ä¢ {feat}")
            with col2:
                st.write("**Ranking das Vari√°veis:**")
                ranking_df = pd.DataFrame({
                    'Vari√°vel': X.columns,
                    'Ranking': rfe.ranking_,
                    'Selecionada': rfe.support_
                }).sort_values('Ranking')
                st.dataframe(ranking_df.head(10))
    else:
        X_train_selected = X_train_balanced
        X_test_selected = X_test
        selected_features = X.columns.tolist()
    
    # Treinar modelo
    model = LogisticRegression(random_state=random_state, max_iter=1000)
    model.fit(X_train_selected, y_train_balanced)
    
    # Predi√ß√µes
    y_pred = model.predict(X_test_selected)
    y_pred_proba = model.predict_proba(X_test_selected)[:, 1]
    
    # M√©tricas de avalia√ß√£o
    st.subheader("üìä M√©tricas de Avalia√ß√£o")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        accuracy = accuracy_score(y_test, y_pred)
        st.markdown(f"""
        <div class="metric-container">
            <h3>{accuracy:.3f}</h3>
            <p>Acur√°cia</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        precision = precision_score(y_test, y_pred)
        st.markdown(f"""
        <div class="metric-container">
            <h3>{precision:.3f}</h3>
            <p>Precis√£o</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        recall = recall_score(y_test, y_pred)
        st.markdown(f"""
        <div class="metric-container">
            <h3>{recall:.3f}</h3>
            <p>Recall</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        auc = roc_auc_score(y_test, y_pred_proba)
        st.markdown(f"""
        <div class="metric-container">
            <h3>{auc:.3f}</h3>
            <p>AUC-ROC</p>
        </div>
        """, unsafe_allow_html=True)
    
    # Gr√°ficos de avalia√ß√£o
    col1, col2 = st.columns(2)
    
    with col1:
        # Matriz de confus√£o
        cm = confusion_matrix(y_test, y_pred)
        fig = px.imshow(cm, 
                       text_auto=True, 
                       aspect="auto",
                       title="Matriz de Confus√£o",
                       labels=dict(x="Predito", y="Real"),
                       x=['N√£o Cancelado', 'Cancelado'],
                       y=['N√£o Cancelado', 'Cancelado'])
        st.plotly_chart(fig)
    
    with col2:
        # Curva ROC
        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
        fig = go.Figure()
        fig.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines', 
                               name=f'ROC (AUC = {auc:.3f})'))
        fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', 
                               line=dict(dash='dash'), name='Aleat√≥rio'))
        fig.update_layout(title="Curva ROC",
                         xaxis_title="Taxa de Falsos Positivos",
                         yaxis_title="Taxa de Verdadeiros Positivos")
        st.plotly_chart(fig)
    
    # Interpreta√ß√£o dos coeficientes
    st.subheader("üîç Interpreta√ß√£o dos Coeficientes")
    
    if apply_rfe:
        coef_df = pd.DataFrame({
            'Vari√°vel': selected_features,
            'Coeficiente': model.coef_[0],
            'Odds Ratio': np.exp(model.coef_[0]),
            'Impacto': ['Aumenta' if x > 0 else 'Diminui' for x in model.coef_[0]]
        })
    else:
        coef_df = pd.DataFrame({
            'Vari√°vel': X.columns,
            'Coeficiente': model.coef_[0],
            'Odds Ratio': np.exp(model.coef_[0]),
            'Impacto': ['Aumenta' if x > 0 else 'Diminui' for x in model.coef_[0]]
        })
    
    coef_df['Import√¢ncia_Abs'] = np.abs(coef_df['Coeficiente'])
    coef_df = coef_df.sort_values('Import√¢ncia_Abs', ascending=False)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**Top 10 Vari√°veis Mais Importantes:**")
        st.dataframe(coef_df.head(10)[['Vari√°vel', 'Coeficiente', 'Odds Ratio', 'Impacto']])
    
    with col2:
        # Gr√°fico de import√¢ncia
        top_features = coef_df.head(10)
        fig = px.bar(top_features, x='Coeficiente', y='Vari√°vel', orientation='h',
                    title="Import√¢ncia das Vari√°veis",
                    color='Coeficiente', color_continuous_scale='RdBu')
        st.plotly_chart(fig)
    
    # An√°lise com Statsmodels
    st.subheader("üìà An√°lise Estat√≠stica Detalhada")
    
    with st.expander("üîç Ver Resultado Completo do Statsmodels"):
        # Recriar modelo com statsmodels
        if apply_rfe:
            X_sm = pd.DataFrame(X_train_selected, columns=selected_features)
        else:
            X_sm = X_train_balanced
        
        X_sm_const = sm.add_constant(X_sm)
        logit_model = sm.Logit(y_train_balanced, X_sm_const)
        result = logit_model.fit(disp=0)
        
        st.text(str(result.summary()))
        
        # Tabela de coeficientes com signific√¢ncia
        coef_summary = pd.DataFrame({
            'Vari√°vel': result.params.index,
            'Coeficiente': result.params.values,
            'Erro Padr√£o': result.bse.values,
            'z-value': result.tvalues.values,
            'P-valor': result.pvalues.values,
            'Odds Ratio': np.exp(result.params.values),
            'Significante (Œ±=0.05)': result.pvalues.values < 0.05
        })
        
        st.write("**Resumo dos Coeficientes:**")
        st.dataframe(coef_summary)
    
    # Curvas log√≠sticas
    st.subheader("üìà Curvas Log√≠sticas")
    
    # Selecionar vari√°veis para curvas log√≠sticas
    numeric_selected = [col for col in selected_features if col in data.select_dtypes(include=[np.number]).columns]
    
    if len(numeric_selected) >= 3:
        vars_for_curves = st.multiselect(
            "Selecione at√© 3 vari√°veis para gerar curvas log√≠sticas:",
            numeric_selected,
            default=numeric_selected[:3]
        )
        
        if vars_for_curves:
            fig = make_subplots(
                rows=1, cols=len(vars_for_curves),
                subplot_titles=vars_for_curves
            )
            
            for i, var in enumerate(vars_for_curves):
                var_idx = selected_features.index(var) if var in selected_features else None
                if var_idx is not None:
                    var_range = np.linspace(data[var].min(), data[var].max(), 100)
                    
                    # Criar matriz para predi√ß√£o mantendo outras vari√°veis na m√©dia
                    X_pred = np.zeros((100, len(selected_features)))
                    for j, feat in enumerate(selected_features):
                        if feat == var:
                            X_pred[:, j] = var_range
                        else:
                            X_pred[:, j] = X_train_balanced[feat].mean() if feat in X_train_balanced.columns else 0
                    
                    # Predizer probabilidades
                    probs = model.predict_proba(X_pred)[:, 1]
                    
                    fig.add_trace(
                        go.Scatter(x=var_range, y=probs, mode='lines', name=var),
                        row=1, col=i+1
                    )
            
            fig.update_layout(height=400, showlegend=False)
            fig.update_xaxes(title_text="Valor da Vari√°vel")
            fig.update_yaxes(title_text="Probabilidade de Cancelamento")
            st.plotly_chart(fig, use_container_width=True)

elif page == "üîç Valida√ß√£o de Pressupostos":
    st.header("üîç Valida√ß√£o dos Pressupostos da Regress√£o Log√≠stica")
    
    # Preparar dados para an√°lise
    df_processed = prepare_data(data)
    X = df_processed.drop('is_canceled', axis=1)
    y = df_processed['is_canceled']
    
    st.subheader("1Ô∏è‚É£ Balanceamento da Vari√°vel Dependente")
    
    # An√°lise do balanceamento
    class_counts = y.value_counts()
    balance_ratio = min(class_counts) / max(class_counts)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Classe 0 (N√£o Cancelado)", class_counts[0])
    with col2:
        st.metric("Classe 1 (Cancelado)", class_counts[1])
    with col3:
        st.metric("Raz√£o de Balanceamento", f"{balance_ratio:.2f}")
    
    if balance_ratio < 0.5:
        st.markdown("""
        <div class="warning-box">
            <strong>‚ö†Ô∏è Aviso:</strong> Os dados est√£o desbalanceados. 
            Recomenda-se aplicar SMOTE ou outras t√©cnicas de balanceamento.
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown("""
        <div class="success-box">
            <strong>‚úÖ Bom:</strong> Os dados est√£o razoavelmente balanceados.
        </div>
        """, unsafe_allow_html=True)
    
    # Visualiza√ß√£o do balanceamento
    fig = px.pie(values=class_counts.values, names=['N√£o Cancelado', 'Cancelado'],
                title="Distribui√ß√£o da Vari√°vel Dependente")
    st.plotly_chart(fig)
    
    st.subheader("2Ô∏è‚É£ Multicolinearidade (VIF)")
    
    # Calcular VIF apenas para vari√°veis num√©ricas
    numeric_cols = X.select_dtypes(include=[np.number]).columns
    X_numeric = X[numeric_cols]
    
    if len(X_numeric.columns) > 1:
        vif_df = calculate_vif(X_numeric)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**Fatores de Infla√ß√£o da Vari√¢ncia (VIF):**")
            st.dataframe(vif_df)
            
            # Interpreta√ß√£o do VIF
            high_vif = vif_df[vif_df['VIF'] > 10]
            if len(high_vif) > 0:
                st.markdown("""
                <div class="warning-box">
                    <strong>‚ö†Ô∏è Multicolinearidade detectada:</strong><br>
                    Vari√°veis com VIF > 10 podem causar problemas de multicolinearidade.
                </div>
                """, unsafe_allow_html=True)
            else:
                st.markdown("""
                <div class="success-box">
                    <strong>‚úÖ Sem multicolinearidade:</strong><br>
                    Todas as vari√°veis t√™m VIF < 10.
                </div>
                """, unsafe_allow_html=True)
        
        with col2:
            # Gr√°fico VIF
            fig = px.bar(vif_df, x='VIF', y='Vari√°vel', orientation='h',
                        title="Fatores de Infla√ß√£o da Vari√¢ncia")
            fig.add_vline(x=10, line_dash="dash", line_color="red", 
                         annotation_text="Limite cr√≠tico (VIF=10)")
            st.plotly_chart(fig)
    
    st.subheader("3Ô∏è‚É£ Linearidade no Logit")
    
    st.write("""
    Para vari√°veis cont√≠nuas, verificamos se existe uma rela√ß√£o linear entre a vari√°vel 
    e o log-odds da vari√°vel dependente.
    """)
    
    # Selecionar vari√°veis cont√≠nuas para teste de linearidade
    continuous_vars = st.multiselect(
        "Selecione vari√°veis cont√≠nuas para an√°lise de linearidade:",
        numeric_cols.tolist(),
        default=numeric_cols.tolist()[:3] if len(numeric_cols) >= 3 else numeric_cols.tolist()
    )
    
    if continuous_vars:
        fig = make_subplots(
            rows=1, cols=len(continuous_vars),
            subplot_titles=continuous_vars
        )
        
        for i, var in enumerate(continuous_vars):
            # Criar bins para a vari√°vel
            bins = pd.qcut(X[var], q=10, duplicates='drop')
            logit_values = []
            bin_centers = []
            
            for bin_val in bins.cat.categories:
                mask = (X[var] >= bin_val.left) & (X[var] <= bin_val.right)
                if mask.sum() > 0:
                    prob = y[mask].mean()
                    if 0 < prob < 1:  # Evitar log(0) ou log(inf)
                        logit = np.log(prob / (1 - prob))
                        logit_values.append(logit)
                        bin_centers.append((bin_val.left + bin_val.right) / 2)
            
            if len(logit_values) > 2:
                fig.add_trace(
                    go.Scatter(x=bin_centers, y=logit_values, mode='markers+lines', name=var),
                    row=1, col=i+1
                )
        
        fig.update_layout(height=400, showlegend=False)
        fig.update_xaxes(title_text="Valor da Vari√°vel")
        fig.update_yaxes(title_text="Log-odds")
        st.plotly_chart(fig, use_container_width=True)
        
        st.markdown("""
        <div class="insight-box">
            <strong>üí° Interpreta√ß√£o:</strong> Se os pontos seguem aproximadamente uma linha reta, 
            o pressuposto de linearidade no logit √© satisfeito.
        </div>
        """, unsafe_allow_html=True)
    
    st.subheader("4Ô∏è‚É£ Outliers e Observa√ß√µes Influentes")
    
    # An√°lise de outliers usando IQR
    outlier_summary = []
    
    for col in numeric_cols:
        Q1 = X[col].quantile(0.25)
        Q3 = X[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        outliers = ((X[col] < lower_bound) | (X[col] > upper_bound)).sum()
        outlier_pct = (outliers / len(X)) * 100
        
        outlier_summary.append({
            'Vari√°vel': col,
            'Outliers': outliers,
            'Percentual': f"{outlier_pct:.1f}%"
        })
    
    outlier_df = pd.DataFrame(outlier_summary)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**Resumo de Outliers:**")
        st.dataframe(outlier_df)
    
    with col2:
        # Gr√°fico de outliers
        fig = px.bar(outlier_df, x='Vari√°vel', y='Outliers',
                    title="N√∫mero de Outliers por Vari√°vel")
        st.plotly_chart(fig)
    
    st.subheader("üìã Resumo da Valida√ß√£o de Pressupostos")
    
    # Criar resumo final
    assumptions_check = []
    
    # Balanceamento
    balance_status = "‚úÖ Aprovado" if balance_ratio >= 0.5 else "‚ö†Ô∏è Aten√ß√£o necess√°ria"
    assumptions_check.append(["Balanceamento", balance_status, f"Raz√£o: {balance_ratio:.2f}"])
    
    # Multicolinearidade
    if len(X_numeric.columns) > 1:
        max_vif = vif_df['VIF'].max()
        vif_status = "‚úÖ Aprovado" if max_vif < 10 else "‚ö†Ô∏è Multicolinearidade detectada"
        assumptions_check.append(["Multicolinearidade", vif_status, f"VIF m√°ximo: {max_vif:.2f}"])
    
    # Outliers
    total_outliers = outlier_df['Outliers'].sum()
    outlier_pct_total = (total_outliers / (len(X) * len(numeric_cols))) * 100
    outlier_status = "‚úÖ Aprovado" if outlier_pct_total < 5 else "‚ö†Ô∏è Muitos outliers"
    assumptions_check.append(["Outliers", outlier_status, f"Total: {total_outliers} ({outlier_pct_total:.1f}%)"])
    
    assumptions_df = pd.DataFrame(assumptions_check, columns=['Pressuposto', 'Status', 'Detalhes'])
    st.dataframe(assumptions_df)

elif page == "üíº Recomenda√ß√µes Estrat√©gicas":
    st.header("üíº Recomenda√ß√µes Estrat√©gicas para Gest√£o Hoteleira")
    
    # Preparar dados e modelo simplificado para demonstra√ß√£o
    df_processed = prepare_data(data)
    X = df_processed.drop('is_canceled', axis=1)
    y = df_processed['is_canceled']
    
    # Treinar modelo rapidamente
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
    model = LogisticRegression(random_state=42, max_iter=1000)
    model.fit(X_train, y_train)
    
    # Calcular feature importance
    feature_importance = pd.DataFrame({
        'Feature': X.columns,
        'Importance': np.abs(model.coef_[0])
    }).sort_values('Importance', ascending=False)
    
    st.subheader("üéØ Fatores de Maior Impacto no Cancelamento")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**Top 10 Fatores Mais Importantes:**")
        top_features = feature_importance.head(10)
        
        for i, row in top_features.iterrows():
            coef = model.coef_[0][X.columns.get_loc(row['Feature'])]
            impact = "Aumenta" if coef > 0 else "Reduz"
            st.write(f"‚Ä¢ **{row['Feature']}**: {impact} cancelamento")
    
    with col2:
        fig = px.bar(top_features, x='Importance', y='Feature', orientation='h',
                    title="Import√¢ncia dos Fatores")
        st.plotly_chart(fig)
    
    st.subheader("üè® Recomenda√ß√µes por Categoria")
    
    tab1, tab2, tab3, tab4 = st.tabs(["üìÖ Gest√£o de Reservas", "üí∞ Pricing", "üë• Atendimento", "üìä Operacional"])
    
    with tab1:
        st.markdown("""
        <div class="insight-box">
            <h4>üìÖ Gest√£o de Reservas</h4>
            
            <strong>Recomenda√ß√µes baseadas no modelo:</strong>
            
            ‚Ä¢ <strong>Lead Time Alto:</strong> Reservas com lead time > 60 dias t√™m maior probabilidade de cancelamento
              - Implementar confirma√ß√£o autom√°tica 30 dias antes da chegada
              - Oferecer flexibilidade nas pol√≠ticas de cancelamento para reservas antecipadas
            
            ‚Ä¢ <strong>Altera√ß√µes na Reserva:</strong> Cada mudan√ßa aumenta a probabilidade de cancelamento
              - Limitar n√∫mero de altera√ß√µes gratuitas
              - Oferecer incentivos para reservas sem altera√ß√µes
            
            ‚Ä¢ <strong>Hist√≥rico de Cancelamentos:</strong> Clientes com cancelamentos anteriores s√£o de maior risco
              - Solicitar dep√≥sito n√£o-reembols√°vel para clientes com hist√≥rico
              - Implementar programa de fidelidade para melhorar reten√ß√£o
        </div>
        """, unsafe_allow_html=True)
    
    with tab2:
        st.markdown("""
        <div class="insight-box">
            <h4>üí∞ Estrat√©gias de Pricing</h4>
            
            <strong>Otimiza√ß√£o baseada no risco de cancelamento:</strong>
            
            ‚Ä¢ <strong>Pre√ßos Din√¢micos:</strong> Ajustar pre√ßos com base no perfil de risco
              - Descontos para perfis de baixo risco de cancelamento
              - Sobretaxa para perfis de alto risco
            
            ‚Ä¢ <strong>Pacotes de Reten√ß√£o:</strong> 
              - Oferecer upgrades gratuitos para reservas com baixa probabilidade de cancelamento
              - Criar pacotes "n√£o-reembols√°veis" com desconto significativo
            
            ‚Ä¢ <strong>Pol√≠ticas de Cancelamento:</strong>
              - Pol√≠ticas mais flex√≠veis para clientes de baixo risco
              - Pol√≠ticas mais restritivas para segmentos de alto risco
        </div>
        """, unsafe_allow_html=True)
    
    with tab3:
        st.markdown("""
        <div class="insight-box">
            <h4>üë• Estrat√©gias de Atendimento</h4>
            
            <strong>Personaliza√ß√£o do atendimento por risco:</strong>
            
            ‚Ä¢ <strong>Alto Risco de Cancelamento:</strong>
              - Contato proativo 15-7 dias antes da chegada
              - Oferecer servi√ßos adicionais (transfers, restaurantes)
              - Verificar necessidades especiais
            
            ‚Ä¢ <strong>Solicita√ß√µes Especiais:</strong> Clientes com solicita√ß√µes especiais cancelam menos
              - Incentivar solicita√ß√µes especiais no momento da reserva
              - Facilitar processo de solicita√ß√µes personalizadas
            
            ‚Ä¢ <strong>Segmenta√ß√£o de Clientes:</strong>
              - Atendimento VIP para clientes corporativos (menor risco)
              - Acompanhamento especial para grupos (maior risco)
        </div>
        """, unsafe_allow_html=True)
    
    with tab4:
        st.markdown("""
        <div class="insight-box">
            <h4>üìä Otimiza√ß√µes Operacionais</h4>
            
            <strong>Gest√£o de capacidade e overbooking:</strong>
            
            ‚Ä¢ <strong>Overbooking Inteligente:</strong>
              - Taxa de overbooking baseada no perfil de risco das reservas
              - Monitoramento em tempo real da probabilidade de no-shows
            
            ‚Ä¢ <strong>Aloca√ß√£o de Quartos:</strong>
              - Priorizar melhores quartos para reservas de baixo risco
              - Manter flexibilidade para upgrades de √∫ltima hora
            
            ‚Ä¢ <strong>Staffing:</strong>
              - Ajustar equipe com base na previs√£o de ocupa√ß√£o real
              - Planejar check-ins com base na probabilidade de chegada
            
            ‚Ä¢ <strong>Inventory Management:</strong>
              - Liberar quartos com base em previs√µes de cancelamento
              - Otimizar vendas de √∫ltima hora
        </div>
        """, unsafe_allow_html=True)
    
    st.subheader("üìà Impacto Financeiro Estimado")
    
    # Calcular m√©tricas de impacto
    total_reservas = len(data)
    total_canceladas = data['is_canceled'].sum()
    taxa_cancelamento_atual = total_canceladas / total_reservas
    
    if 'adr' in data.columns:
        adr_medio = data['adr'].mean()
        receita_perdida_atual = total_canceladas * adr_medio
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric(
                "Taxa de Cancelamento Atual",
                f"{taxa_cancelamento_atual:.1%}",
                help="Percentual de reservas canceladas"
            )
        
        with col2:
            st.metric(
                "Receita Perdida (estimada)",
                f"${receita_perdida_atual:,.0f}",
                help="Receita perdida por cancelamentos"
            )
        
        with col3:
            # Estimativa de melhoria com implementa√ß√£o das recomenda√ß√µes
            melhoria_estimada = 0.15  # 15% de redu√ß√£o nos cancelamentos
            nova_taxa = taxa_cancelamento_atual * (1 - melhoria_estimada)
            receita_recuperada = total_reservas * adr_medio * (taxa_cancelamento_atual - nova_taxa)
            
            st.metric(
                "Receita Recuper√°vel",
                f"${receita_recuperada:,.0f}",
                f"-{melhoria_estimada:.0%} cancelamentos"
            )
    
    st.subheader("üéØ Plano de Implementa√ß√£o")
    
    implementation_plan = pd.DataFrame({
        'Fase': ['Fase 1', 'Fase 2', 'Fase 3', 'Fase 4'],
        'Per√≠odo': ['0-2 meses', '2-4 meses', '4-8 meses', '8-12 meses'],
        'A√ß√µes Principais': [
            'Implementar sistema de scoring de risco, pol√≠ticas diferenciadas de cancelamento',
            'Desenvolver automa√ß√£o de contatos proativos, sistema de overbooking inteligente',
            'Implementar pricing din√¢mico baseado em risco, programa de fidelidade',
            'Otimiza√ß√£o cont√≠nua com ML, integra√ß√£o com sistemas de gest√£o'
        ],
        'Investimento': ['Baixo', 'M√©dio', 'Alto', 'M√©dio'],
        'ROI Esperado': ['5-10%', '10-15%', '15-25%', '25-35%']
    })
    
    st.dataframe(implementation_plan)

elif page == "üéØ Simulador de Cen√°rios":
    st.header("üéØ Simulador de Cen√°rios")
    
    st.write("""
    Use este simulador para testar diferentes cen√°rios e ver como as mudan√ßas 
    nos par√¢metros afetam a probabilidade de cancelamento.
    """)
    
    # Preparar modelo
    df_processed = prepare_data(data)
    X = df_processed.drop('is_canceled', axis=1)
    y = df_processed['is_canceled']
    
    model = LogisticRegression(random_state=42, max_iter=1000)
    model.fit(X, y)
    
    st.subheader("üîß Configure o Cen√°rio")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**Caracter√≠sticas da Reserva:**")
        
        # Inputs principais
        lead_time = st.slider("Lead Time (dias)", 0, 365, 30)
        
        if 'adr' in data.columns:
            adr = st.slider("ADR (Tarifa M√©dia)", 
                           int(data['adr'].min()), 
                           int(data['adr'].max()), 
                           int(data['adr'].mean()))
        else:
            adr = st.slider("ADR (Tarifa M√©dia)", 50, 500, 100)
        
        adults = st.selectbox("N√∫mero de Adultos", [1, 2, 3, 4], index=1)
        children = st.selectbox("N√∫mero de Crian√ßas", [0, 1, 2, 3])
        
        if 'total_of_special_requests' in data.columns:
            special_requests = st.slider("Solicita√ß√µes Especiais", 0, 5, 0)
        
        booking_changes = st.slider("Altera√ß√µes na Reserva", 0, 5, 0)
        
        if 'previous_cancellations' in data.columns:
            prev_cancellations = st.slider("Cancelamentos Anteriores", 0, 5, 0)
    
    with col2:
        st.write("**Caracter√≠sticas Categ√≥ricas:**")
        
        if 'hotel' in data.columns:
            hotel_type = st.selectbox("Tipo de Hotel", data['hotel'].unique())
        
        if 'market_segment' in data.columns:
            market_segment = st.selectbox("Segmento de Mercado", data['market_segment'].unique())
        
        if 'customer_type' in data.columns:
            customer_type = st.selectbox("Tipo de Cliente", data['customer_type'].unique())
        
        if 'arrival_date_month' in data.columns:
            arrival_month = st.selectbox("M√™s de Chegada", data['arrival_date_month'].unique())
        
        repeated_guest = st.selectbox("Cliente Repetido", [0, 1], format_func=lambda x: "N√£o" if x == 0 else "Sim")
    
    # Bot√£o para calcular
    if st.button("üîÆ Calcular Probabilidade de Cancelamento", type="primary"):
        
        # Criar vetor de caracter√≠sticas baseado no input
        # Nota: Este √© um exemplo simplificado. Na implementa√ß√£o real, 
        # voc√™ precisaria criar o vetor completo com todas as features do modelo
        
        # Para demonstra√ß√£o, vamos usar uma aproxima√ß√£o baseada nas vari√°veis principais
        features_dict = {}
        
        # Preencher com valores padr√£o e depois atualizar com inputs do usu√°rio
        for col in X.columns:
            if 'lead_time' in col.lower():
                features_dict[col] = lead_time
            elif 'adr' in col.lower():
                features_dict[col] = adr
            elif 'adults' in col.lower():
                features_dict[col] = adults
            elif 'children' in col.lower():
                features_dict[col] = children
            elif 'booking_changes' in col.lower():
                features_dict[col] = booking_changes
            elif 'special_requests' in col.lower() and 'total_of_special_requests' in data.columns:
                features_dict[col] = special_requests
            elif 'previous_cancellations' in col.lower() and 'previous_cancellations' in data.columns:
                features_dict[col] = prev_cancellations
            elif 'repeated_guest' in col.lower():
                features_dict[col] = repeated_guest
            else:
                # Para outras colunas, usar a m√©dia ou moda
                if col in data.select_dtypes(include=[np.number]).columns:
                    features_dict[col] = data[col].mean()
                else:
                    features_dict[col] = 0
        
        # Criar array de features
        feature_vector = np.array([features_dict.get(col, 0) for col in X.columns]).reshape(1, -1)
        
        # Fazer predi√ß√£o
        prob_cancelamento = model.predict_proba(feature_vector)[0, 1]
        
        # Exibir resultado
        st.subheader("üìä Resultado da Simula√ß√£o")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            # Gauge chart para probabilidade
            fig = go.Figure(go.Indicator(
                mode = "gauge+number",
                value = prob_cancelamento * 100,
                domain = {'x': [0, 1], 'y': [0, 1]},
                title = {'text': "Probabilidade de Cancelamento (%)"},
                gauge = {
                    'axis': {'range': [None, 100]},
                    'bar': {'color': "darkblue"},
                    'steps': [
                        {'range': [0, 25], 'color': "lightgreen"},
                        {'range': [25, 50], 'color': "yellow"},
                        {'range': [50, 75], 'color': "orange"},
                        {'range': [75, 100], 'color': "red"}
                    ],
                    'threshold': {
                        'line': {'color': "red", 'width': 4},
                        'thickness': 0.75,
                        'value': 90
                    }
                }
            ))
            fig.update_layout(height=300)
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # Classifica√ß√£o de risco
            if prob_cancelamento < 0.25:
                risco = "BAIXO"
                cor = "success"
                icone = "‚úÖ"
            elif prob_cancelamento < 0.5:
                risco = "M√âDIO"
                cor = "warning"
                icone = "‚ö†Ô∏è"
            elif prob_cancelamento < 0.75:
                risco = "ALTO"
                cor = "warning"
                icone = "üî∂"
            else:
                risco = "CR√çTICO"
                cor = "error"
                icone = "üö®"
            
            st.markdown(f"""
            <div class="metric-container">
                <h2>{icone} {risco}</h2>
                <p>N√≠vel de Risco</p>
                <small>Probabilidade: {prob_cancelamento:.1%}</small>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            # A√ß√µes recomendadas
            if prob_cancelamento < 0.25:
                acoes = [
                    "‚úÖ Processar reserva normalmente",
                    "üí° Considerar upgrade gratuito",
                    "üìß Enviar email de confirma√ß√£o padr√£o"
                ]
            elif prob_cancelamento < 0.5:
                acoes = [
                    "üìû Contato 48h antes da chegada",
                    "üéÅ Oferecer servi√ßos adicionais",
                    "üìù Confirmar detalhes da reserva"
                ]
            elif prob_cancelamento < 0.75:
                acoes = [
                    "üîí Solicitar garantia adicional",
                    "üìû Contato 72h antes da chegada",
                    "üí∞ Oferecer upgrade pago"
                ]
            else:
                acoes = [
                    "üö® Solicitar dep√≥sito n√£o-reembols√°vel",
                    "üìû Contato imediato para confirma√ß√£o",
                    "üîÑ Considerar overbooking para esta vaga"
                ]
            
            st.write("**A√ß√µes Recomendadas:**")
            for acao in acoes:
                st.write(f"‚Ä¢ {acao}")
        
        # An√°lise de sensibilidade
        st.subheader("üìà An√°lise de Sensibilidade")
        
        st.write("Veja como mudan√ßas em vari√°veis-chave afetam a probabilidade:")
        
        # Testar varia√ß√£o no lead time
        lead_times = np.arange(0, 200, 10)
        probs_lead = []
        
        for lt in lead_times:
            temp_vector = feature_vector.copy()
            # Encontrar √≠ndice da coluna lead_time (aproxima√ß√£o)
            lead_time_cols = [i for i, col in enumerate(X.columns) if 'lead_time' in col.lower()]
            if lead_time_cols:
                temp_vector[0, lead_time_cols[0]] = lt
            probs_lead.append(model.predict_proba(temp_vector)[0, 1])
        
        fig = go.Figure()
        fig.add_trace(go.Scatter(x=lead_times, y=probs_lead, mode='lines', name='Lead Time'))
        fig.add_hline(y=prob_cancelamento, line_dash="dash", line_color="red", 
                     annotation_text="Cen√°rio Atual")
        fig.update_layout(
            title="Impacto do Lead Time na Probabilidade de Cancelamento",
            xaxis_title="Lead Time (dias)",
            yaxis_title="Probabilidade de Cancelamento"
        )
        st.plotly_chart(fig, use_container_width=True)

# Footer
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666; padding: 1rem;">
    üè® <strong>Sistema de Predi√ß√£o de Cancelamentos</strong><br>
    Desenvolvido para a disciplina de Engenharia de Produ√ß√£o - UnB<br>
    Professor: Jo√£o Gabriel de Moraes Souza
</div>
""", unsafe_allow_html=True)

# Adicionar informa√ß√µes de como usar no sidebar
st.sidebar.markdown("---")
st.sidebar.markdown("""
### üìñ Como usar este dashboard:

1. **üè† Vis√£o Geral**: Explore os dados gerais
2. **üìä An√°lise Explorat√≥ria**: Analise padr√µes nos dados
3. **ü§ñ Modelagem**: Configure e treine modelos
4. **üîç Valida√ß√£o**: Verifique pressupostos estat√≠sticos
5. **üíº Recomenda√ß√µes**: Veja insights de neg√≥cio
6. **üéØ Simulador**: Teste cen√°rios espec√≠ficos

### üéØ Principais recursos:
- An√°lise interativa completa
- Modelagem com SMOTE e RFE
- Valida√ß√£o de pressupostos
- Recomenda√ß√µes estrat√©gicas
- Simulador de cen√°rios
""")

st.sidebar.markdown("---")
st.sidebar.info("""
üí° **Dica**: Use o simulador de cen√°rios para testar 
diferentes perfis de clientes e entender como 
otimizar suas estrat√©gias de gest√£o hoteleira.
""")
